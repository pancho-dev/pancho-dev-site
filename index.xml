<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pancho.dev</title>
    <link>http://pancho.dev/</link>
    <description>Recent content on pancho.dev</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Mar 2020 04:52:30 +0600</lastBuildDate>
    
	<atom:link href="http://pancho.dev/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Testing a reverse http proxy</title>
      <link>http://pancho.dev/posts/testing-a-proxy/</link>
      <pubDate>Mon, 03 Aug 2020 14:05:25 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/testing-a-proxy/</guid>
      <description>Did you ever had trouble with a proxy config? Found that is not simple to test a proxy locally?. Why this? simple, I found many times deploying a proxy configuration to production, even a small change like adding a new path, a redirection or just updating ssl certs, can lead to a disruption or an outage because sometimes it&amp;rsquo;s hard to properly test it before pushing the configuration. So I found a couple od tricks that can help test locally in our laptops or machine before even pushing the code or config giving a safer path to deploy a proxy config.</description>
    </item>
    
    <item>
      <title>What is a lightning post?</title>
      <link>http://pancho.dev/posts/lightning-post/</link>
      <pubDate>Sun, 02 Aug 2020 13:07:20 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/lightning-post/</guid>
      <description>After about 2 months of launching this blog I realized that creating blog content is a time consuming task. While the whole purpose of my blog is to share some of my experiences and it&amp;rsquo;s my own way to contribute to the open source community (most of what I talk about here is open source tech), I figured that I wanted to keep adding content every week, but some weeks it&amp;rsquo;s much harder than other weeks to create a full blown blog post, I write this in my free time so between work and personal life it&amp;rsquo;s hard to keep full blown projects every week.</description>
    </item>
    
    <item>
      <title>Who Stole My Cpu?</title>
      <link>http://pancho.dev/posts/who-stole-my-cpu/</link>
      <pubDate>Thu, 16 Jul 2020 15:51:59 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/who-stole-my-cpu/</guid>
      <description>In a previous post I talked about Taming the cpu metrics, while that post was an overview of cpu metrics I tought it was a good topic to enphasize on the cpu steal metric in linux hosts. This is something I recently found and didn&amp;rsquo;t know it even existed, but it can be very useful when running in virtualized environments and helping us tune either the vm, or the physical host that runs the vms.</description>
    </item>
    
    <item>
      <title>Taming the Cpu Metrics</title>
      <link>http://pancho.dev/posts/taming-the-cpu-metrics/</link>
      <pubDate>Sat, 11 Jul 2020 15:08:51 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/taming-the-cpu-metrics/</guid>
      <description>In a past blog post I talked about The misunderstood load average in linux hosts, while load average is a good metric to watch in linux systems to catch generic performance problems, it does not reveal what the issue might be. This time I will dig more into cpu metrics collected from a linux system and explain them, for this purpose I will use multipass vms, and will be showing metrics from grafana screnshots which take the data from prometheus and prometheus node exporter (this is actually out of the scope of this post).</description>
    </item>
    
    <item>
      <title>What&#39;s a ULID</title>
      <link>http://pancho.dev/posts/whats-ulid/</link>
      <pubDate>Sat, 27 Jun 2020 14:35:31 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/whats-ulid/</guid>
      <description>This time I will talk about someting I found out very recently, and I found interesting to share this information as it might be handy for developers to use when the use case fits.
So this time I will introduce the ulid. Spoiler alert, it&amp;rsquo;s an ID or at least a data structure that can be used to represent an ID. So why do we have another way of expressing an ID, I won&amp;rsquo;t get into too much details into that but yes there are many ways of defining ids, it can be numerical, using UUIDs, etc.</description>
    </item>
    
    <item>
      <title>Multipass Microk8s Cluster on multiple nodes</title>
      <link>http://pancho.dev/posts/multipass-microk8s-cluster/</link>
      <pubDate>Sat, 13 Jun 2020 11:37:56 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/multipass-microk8s-cluster/</guid>
      <description>A couple of posts ago I talked about multinode kubernetes clusters and the benefis of them running them for developing automation, testing software and configurations. I still think is that most developers probably don&amp;rsquo;t need this setup or can live with a simpler setup. My motivation is because I work on cloud infrastructure and automation of delployments, databases, and lots of complex scenarios that running single node k8s cluster doesn&amp;rsquo;t fit my needs.</description>
    </item>
    
    <item>
      <title>The misunderstood load average in linux hosts</title>
      <link>http://pancho.dev/posts/linux-load-average/</link>
      <pubDate>Sun, 07 Jun 2020 20:02:27 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/linux-load-average/</guid>
      <description>Ever wondered when someone runs the command uptime in a linux host what the values in the load average: section mean? well I have wondered about it many times in my carreer. And this should be a simple question to ask a seasoned linux administrator or developer, right? well it&amp;rsquo;s not entirely true, as the load average value in a linux hosts probably is the most misunderstood term and often associated with the wrong concepts.</description>
    </item>
    
    <item>
      <title>Creating Kubernetes Kind Cluster</title>
      <link>http://pancho.dev/posts/creating-kubernetes-kind-cluster/</link>
      <pubDate>Sat, 30 May 2020 15:11:30 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/creating-kubernetes-kind-cluster/</guid>
      <description>In an earlier post I showed how to create Multinode k8s cluster using ignite and k3s, while this was a good experience I needed to test some other tools, and this time I decided to go for kind (kubernetes in docker). Which looks like a good approach to work with clusters locally and it will still be lightweight as the kubernetes &amp;ldquo;nodes&amp;rdquo; will be actually running as docker containers. This at first glance looks like a easier approach and seems to work in a similar way in Mac, linux or wirndows, which gives a great advantage.</description>
    </item>
    
    <item>
      <title>Multinode k8s cluster using ignite and k3s</title>
      <link>http://pancho.dev/posts/multinode-k8s-ignite-k3s/</link>
      <pubDate>Sun, 17 May 2020 18:22:05 -0300</pubDate>
      
      <guid>http://pancho.dev/posts/multinode-k8s-ignite-k3s/</guid>
      <description>Sometimes if you are working with kubernetes, or developing applications that require a multinode setup to test some functionality running a multinode cluster is a must, in some cases you could use kind which you can spin up multinode/multimaster clusters on docker, however there might be scenarios were you still need to test or develop functions that need the real feel of a cluster with multiple nodes.
In the past I have run this in my local environment running vms with vagrant and virtualbox, that worked very well, and I still use it for some special scenarios.</description>
    </item>
    
  </channel>
</rss>