<!DOCTYPE html>
<html lang="en-us">

<head><title>
    Multinode K8s Cluster Using Ignite and K3s | 
    
    pancho.dev</title>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<meta name="description" content="Sometimes if you are working with kubernetes, or developing applications that require a multinode setup to test some functionality running a multinode cluster is a must, in some cases you could use kind which you can spin up multinode/multimaster clusters on docker, however there might be scenarios were you still need to test or develop functions that need the real feel of a cluster with multiple nodes.
In the past I have run this in my local environment running vms with vagrant and virtualbox, that worked very well, and I still use it for some special scenarios.
    ">


<meta property="og:title" content="Multinode k8s cluster using ignite and k3s" />
<meta property="og:description" content="Sometimes if you are working with kubernetes, or developing applications that require a multinode setup to test some functionality running a multinode cluster is a must, in some cases you could use kind which you can spin up multinode/multimaster clusters on docker, however there might be scenarios were you still need to test or develop functions that need the real feel of a cluster with multiple nodes.
In the past I have run this in my local environment running vms with vagrant and virtualbox, that worked very well, and I still use it for some special scenarios." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://pancho.dev/posts/multinode-k8s-ignite-k3s/" />
<meta property="article:published_time" content="2020-05-17T18:22:05-03:00" />
<meta property="article:modified_time" content="2020-05-17T18:22:05-03:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Multinode k8s cluster using ignite and k3s"/>
<meta name="twitter:description" content="Sometimes if you are working with kubernetes, or developing applications that require a multinode setup to test some functionality running a multinode cluster is a must, in some cases you could use kind which you can spin up multinode/multimaster clusters on docker, however there might be scenarios were you still need to test or develop functions that need the real feel of a cluster with multiple nodes.
In the past I have run this in my local environment running vms with vagrant and virtualbox, that worked very well, and I still use it for some special scenarios."/>

<meta itemprop="name" content="Multinode k8s cluster using ignite and k3s">
<meta itemprop="description" content="Sometimes if you are working with kubernetes, or developing applications that require a multinode setup to test some functionality running a multinode cluster is a must, in some cases you could use kind which you can spin up multinode/multimaster clusters on docker, however there might be scenarios were you still need to test or develop functions that need the real feel of a cluster with multiple nodes.
In the past I have run this in my local environment running vms with vagrant and virtualbox, that worked very well, and I still use it for some special scenarios.">
<meta itemprop="datePublished" content="2020-05-17T18:22:05-03:00" />
<meta itemprop="dateModified" content="2020-05-17T18:22:05-03:00" />
<meta itemprop="wordCount" content="2406">



<meta itemprop="keywords" content="linux,kubernetes," />
<link rel="canonical" href="http://pancho.dev/posts/multinode-k8s-ignite-k3s/" />

<link rel="icon" type="image/png" href="http://pancho.dev/image/favicon.ico">

<link rel="stylesheet" href="/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/bulma.min.css">



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-920705-12', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script src=/js/ramium.js></script>
<link rel="stylesheet" href=/css/ramium.css>





</head>

<body><nav class="navbar is-dark" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href=/>
      
      <strong>pancho.dev </strong>
      
    </a>

    <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false"
      data-target="navbarBasicExample">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

  <div id="navbarBasicExample" class="navbar-menu">
    <div class="navbar-start">
      
      
      <a class="navbar-item" href="/">Home</a>
      
      
      
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">Blog</a>
        <div class="navbar-dropdown">
          
          <a class="navbar-item" href="/posts/">All Posts</a>
          
        </div>
      </div>
      
      
    </div>

    <div class="navbar-end">
      

      
    </div>
  </div>
</nav><div class="columns is-centered">
        <div id="page-body" class="column is-7">

<div class="content blog">
    <h1>Multinode K8s Cluster Using Ignite and K3s</h1>

    <div id="infobar" class="level is-mobile">
        <div class="level-left">
            
            <div class="level-item">
                <p class="subtitle info date">May 17, 2020
                </p>
            </div>
            

            <div class="level-item">
                <p class="subtitle info">
                    13 mins read
                </p>
            </div>
        </div>
        <div class="level-right is-hidden-touch">
            <div class="tags">
                
                <a class="tag is-dark is-rounded" href="/tags/linux">Linux</a>
                
                <a class="tag is-dark is-rounded" href="/tags/kubernetes">Kubernetes</a>
                
            </div>
        </div>
    </div>

    <div class="tags is-hidden-desktop">
        
        <a class="tag is-dark is-rounded" href="/tags/linux">Linux</a>
        
        <a class="tag is-dark is-rounded" href="/tags/kubernetes">Kubernetes</a>
        
    </div>

    <div class="blog-text">
        

        <p>Sometimes if you are working with kubernetes, or developing applications that require a multinode setup to test some functionality running a multinode cluster is a must, in some cases you could use <a href="https://kind.sigs.k8s.io/docs/user/quick-start/">kind</a> which you can spin up multinode/multimaster clusters on docker, however there might be scenarios were you still need to test or develop functions that need the real feel of a cluster with multiple nodes.<br>
In the past I have run this in my local environment running vms with vagrant and virtualbox, that worked very well, and I still use it for some special scenarios. But I needed something I could run more workers/masters on my local laptop. One clear example is that I wanted to test the <a href="https://access.crunchydata.com/documentation/postgres-operator">postgres operator from crunchydata</a> that allows to create a postgres cluster with a stanby cluster in a different k8s cluster. Or try <a href="https://github.com/squat/kilo">kilo</a> to setup encrypted communications between pods and test the multi cluster setup. Another use case was that I wanted to play with CNI plugins or some use some other advanced features, and the setup I will explain in this post allows more felxibility to do so.<br>
My need could be solved by vagrant and virtualbox, and in fact is a great aproach and very easy to setup everything as code in an automated fashion. But I wanted to take my laptop to the next level with something more efficient and I found a great project that allows to run <a href="https://firecracker-microvm.github.io/">firecracker</a> micro-vms in a way that is very similar to running docker containers. The project is called <a href="https://github.com/weaveworks/ignite">ignite</a> and you will have in no time vms running using very little resources which allows to run much more worker nodes and multiple clusters at the same time.<br>
We will install ignite in our ubuntu laptop/desktop/server and run a 3 node kubernetes cluster. The following have been tested in my ubuntu 18.04 server I run at home.</p>
<h2 id="requirements">Requirements</h2>
<ul>
<li>amd64 linux machine (No mac support at the moment as firecracker relies on linux kvm). It should be technically possible to run on arm64 as there are binaries for firecracker and some distributions support kvm on arm platforms. I have tried to run on an ubuntu 18.04 and got ignite to work but I was not able to run a vm yet (probably need to build my own image an kernel with arm support)</li>
<li>Ubuntu 18.04 (same steps should work in 20.04 or other ubuntu versions without many changes)</li>
<li>console or ssh and root access to the host where we will install everything</li>
<li>internet access to be able to pull images and software</li>
</ul>
<h1 id="install-ignite">Install ignite</h1>
<p>As mentioned before ignite is a software that can be used to start firecracker micro vms with the <code>look and feel</code> of docker, In fact there are a lot of similarities in the <code>ignite</code> command and the <code>docker</code> command. You can find everything <a href="https://github.com/weaveworks/ignite">https://github.com/weaveworks/ignite</a> and  <a href="https://ignite.readthedocs.io/en/stable/">https://ignite.readthedocs.io/en/stable/</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Become root</span>
sudo -i

<span style="color:#75715e"># Check that cpu has virtualization capabilities</span>
$ lscpu | grep Virtualization
Virtualization:      VT-x

<span style="color:#75715e"># Install Dependencies</span>
$ apt-get update <span style="color:#f92672">&amp;&amp;</span> apt-get install -y --no-install-recommends dmsetup openssh-client git binutils

$ which containerd <span style="color:#f92672">||</span> apt-get install -y --no-install-recommends containerd

<span style="color:#75715e"># Install CNI plugins</span>
$ export CNI_VERSION<span style="color:#f92672">=</span>v0.8.5
$ export ARCH<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span><span style="color:#f92672">[</span> <span style="color:#66d9ef">$(</span>uname -m<span style="color:#66d9ef">)</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;x86_64&#34;</span> <span style="color:#f92672">]</span> <span style="color:#f92672">&amp;&amp;</span> echo amd64 <span style="color:#f92672">||</span> echo arm64<span style="color:#66d9ef">)</span>
$ sudo mkdir -p /opt/cni/bin
$ curl -sSL https://github.com/containernetworking/plugins/releases/download/<span style="color:#e6db74">${</span>CNI_VERSION<span style="color:#e6db74">}</span>/cni-plugins-linux-<span style="color:#e6db74">${</span>ARCH<span style="color:#e6db74">}</span>-<span style="color:#e6db74">${</span>CNI_VERSION<span style="color:#e6db74">}</span>.tgz | sudo tar -xz -C /opt/cni/bin

<span style="color:#75715e"># Install ignite binaries</span>
$ export VERSION<span style="color:#f92672">=</span>v0.6.3
$ export GOARCH<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>go env GOARCH 2&gt;/dev/null <span style="color:#f92672">||</span> echo <span style="color:#e6db74">&#34;amd64&#34;</span><span style="color:#66d9ef">)</span>

$ <span style="color:#66d9ef">for</span> binary in ignite ignited; <span style="color:#66d9ef">do</span>
    echo <span style="color:#e6db74">&#34;Installing </span><span style="color:#e6db74">${</span>binary<span style="color:#e6db74">}</span><span style="color:#e6db74">...&#34;</span>
    curl -sfLo <span style="color:#e6db74">${</span>binary<span style="color:#e6db74">}</span> https://github.com/weaveworks/ignite/releases/download/<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>/<span style="color:#e6db74">${</span>binary<span style="color:#e6db74">}</span>-<span style="color:#e6db74">${</span>GOARCH<span style="color:#e6db74">}</span>
    chmod +x <span style="color:#e6db74">${</span>binary<span style="color:#e6db74">}</span>
    sudo mv <span style="color:#e6db74">${</span>binary<span style="color:#e6db74">}</span> /usr/local/bin
<span style="color:#66d9ef">done</span>
</code></pre></div><p>Check your installation</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ ignite version
Ignite version: version.Info<span style="color:#f92672">{</span>Major:<span style="color:#e6db74">&#34;0&#34;</span>, Minor:<span style="color:#e6db74">&#34;6&#34;</span>, GitVersion:<span style="color:#e6db74">&#34;v0.6.3&#34;</span>, GitCommit:<span style="color:#e6db74">&#34;ed51b9378f6e0982461074734beb145d571d56a6&#34;</span>, GitTreeState:<span style="color:#e6db74">&#34;clean&#34;</span>, BuildDate:<span style="color:#e6db74">&#34;2019-12-10T06:19:57Z&#34;</span>, GoVersion:<span style="color:#e6db74">&#34;go1.12.10&#34;</span>, Compiler:<span style="color:#e6db74">&#34;gc&#34;</span>, Platform:<span style="color:#e6db74">&#34;linux/amd64&#34;</span><span style="color:#f92672">}</span>
Firecracker version: v0.18.1
Runtime: containerd
</code></pre></div><p>If there are any problems please refer to the ignite docs as it is a project under heavy development and there might be breaking changes in the current versions</p>
<h1 id="create-vms">Create vms</h1>
<p>Now that we have ignite installed and ready we can start creating vms for our kubernetes cluster. We will have 1 node named <code>master</code> and 2 worker nodes named <code>worker1</code> and <code>worker2</code></p>
<h3 id="master-node">Master node</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Start the master node</span>
$ sudo ignite run weaveworks/ignite-ubuntu <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --name master <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --cpus <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --memory 2GB <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --size 6GB <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --ssh
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Created VM with ID <span style="color:#e6db74">&#34;a0679083cb8cb9d4&#34;</span> and name <span style="color:#e6db74">&#34;master&#34;</span>
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Networking is handled by <span style="color:#e6db74">&#34;cni&#34;</span>
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Started Firecracker VM <span style="color:#e6db74">&#34;a0679083cb8cb9d4&#34;</span> in a container with ID <span style="color:#e6db74">&#34;ignite-a0679083cb8cb9d4&#34;</span>

<span style="color:#75715e"># log in to the master</span>
$ sudo ignite ssh master

<span style="color:#75715e"># On master vm change hostname</span>
$ hostname master <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>echo <span style="color:#e6db74">&#39;master&#39;</span> &gt; /etc/hostname <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>echo <span style="color:#e6db74">&#39;127.0.0.1 master&#39;</span> &gt;&gt; /etc/hosts

<span style="color:#75715e"># On master vm update the OS</span>
$ apt update <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>apt upgrade -y <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>exit

</code></pre></div><h3 id="worker-node-1">Worker node 1</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Start worked node 1</span>
$ sudo ignite run weaveworks/ignite-ubuntu <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --name worker1 <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --cpus <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --memory 2GB <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --size 6GB <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --ssh
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Created VM with ID <span style="color:#e6db74">&#34;176870ae0df03d49&#34;</span> and name <span style="color:#e6db74">&#34;worker1&#34;</span>
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Networking is handled by <span style="color:#e6db74">&#34;cni&#34;</span>
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Started Firecracker VM <span style="color:#e6db74">&#34;176870ae0df03d49&#34;</span> in a container with ID <span style="color:#e6db74">&#34;ignite-176870ae0df03d49&#34;</span>

<span style="color:#75715e"># log in to the worker node 1</span>
$ sudo ignite ssh worker1

<span style="color:#75715e"># On worker 1 vm change hostname</span>
$ hostname worker1 <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>echo <span style="color:#e6db74">&#39;worker1&#39;</span> &gt; /etc/hostname <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>echo <span style="color:#e6db74">&#39;127.0.0.1 worker1&#39;</span> &gt;&gt; /etc/hosts

<span style="color:#75715e"># On worker1 vm update the OS</span>
$ apt update <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>apt upgrade -y <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>exit

</code></pre></div><h3 id="worker-node-2">Worker node 2</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Start worked node 1</span>
$ sudo ignite run weaveworks/ignite-ubuntu <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --name worker2 <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --cpus <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --memory 2GB <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --size 6GB <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>  --ssh
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Created VM with ID <span style="color:#e6db74">&#34;fa96691aabac2a3f&#34;</span> and name <span style="color:#e6db74">&#34;worker2&#34;</span>
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Networking is handled by <span style="color:#e6db74">&#34;cni&#34;</span>
INFO<span style="color:#f92672">[</span>0001<span style="color:#f92672">]</span> Started Firecracker VM <span style="color:#e6db74">&#34;fa96691aabac2a3f&#34;</span> in a container with ID <span style="color:#e6db74">&#34;ignite-fa96691aabac2a3f&#34;</span>

<span style="color:#75715e"># log in to the worker node 1</span>
$ sudo ignite ssh worker2

<span style="color:#75715e"># On worker 1 vm change hostname</span>
$ hostname worker2 <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>echo <span style="color:#e6db74">&#39;worker2&#39;</span> &gt; /etc/hostname <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>echo <span style="color:#e6db74">&#39;127.0.0.1 worker2&#39;</span> &gt;&gt; /etc/hosts

<span style="color:#75715e"># On worker2 vm update the OS</span>
$ apt update <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>apt upgrade -y <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>exit

</code></pre></div><h1 id="install-k3s">Install k3s</h1>
<p>Now that we have 3 clean vms ready, lets install a kubernetes cluster. For that we will use a lightweight kubernetes distribution called k3s <a href="https://rancher.com/docs/k3s/latest/en/quick-start/">https://rancher.com/docs/k3s/latest/en/quick-start/</a>
Before we start doing the installation we need to run the following to get IP information of the vms</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># we need to list the vms in order to get ip information needed for following steps</span>
$ ignite ps
VM ID			IMAGE				KERNEL					SIZE	CPUS	MEMORY	CREATED		STATUS		IPS				PORTS	NAME
176870ae0df03d49	weaveworks/ignite-ubuntu:latest	weaveworks/ignite-kernel:4.19.47	6.0 GB	1	2.0 GB	8m26s ago	Up 8m26s	10.61.0.3, 127.0.0.1, ::1		worker1
a0679083cb8cb9d4	weaveworks/ignite-ubuntu:latest	weaveworks/ignite-kernel:4.19.47	6.0 GB	1	2.0 GB	14m ago		Up 14m		10.61.0.2, 127.0.0.1, ::1		master
fa96691aabac2a3f	weaveworks/ignite-ubuntu:latest	weaveworks/ignite-kernel:4.19.47	6.0 GB	1	2.0 GB	6m23s ago	Up 6m23s	10.61.0.4, 127.0.0.1, ::1		worker2
</code></pre></div><p>From this command we will need the <code>master</code> node IP which in this case is <code>10.61.0.2</code></p>
<h2 id="install-master">Install Master</h2>
<p>In this tutorial we will run the quick install, if there is a need for a special setup or HA masters please check k3s full documentation for options.<br>
On the master run:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># log in to the master</span>
$ sudo ignite ssh master

<span style="color:#75715e"># Run Install script</span>
$ curl -sfL https://get.k3s.io | sh -

<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Finding release <span style="color:#66d9ef">for</span> channel stable
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Using v1.18.2+k3s1 as release
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Downloading hash https://github.com/rancher/k3s/releases/download/v1.18.2+k3s1/sha256sum-amd64.txt
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Downloading binary https://github.com/rancher/k3s/releases/download/v1.18.2+k3s1/k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Verifying binary download
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Installing k3s to /usr/local/bin/k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/kubectl symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/crictl symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/ctr symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating killall script /usr/local/bin/k3s-killall.sh
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating uninstall script /usr/local/bin/k3s-uninstall.sh
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  env: Creating environment file /etc/systemd/system/k3s.service.env
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  systemd: Creating service file /etc/systemd/system/k3s.service
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  systemd: Enabling k3s unit
Created symlink /etc/systemd/system/multi-user.target.wants/k3s.service → /etc/systemd/system/k3s.service.
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  systemd: Starting k3s


<span style="color:#75715e"># To get the kubectl config, NOTE: that you will need to change the 127.0.0.1 IP with the master ip is you want to run kubectl straight from you laptop. In this tutorial we will run all kubectl commands form the master so there is no need to copy this file anywhere</span>
$ cat /etc/rancher/k3s/k3s.yaml

apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJWekNCL3FBREFnRUNBZ0VBTUFvR0NDcUdTTTQ5QkFNQ01DTXhJVEFmQmdOVkJBTU1HR3N6Y3kxelpYSjIKWlhJdFkyRkFNVFU0T1RjME5EQXhNREFlRncweU1EQTFNVGN4T1RNek16QmFGdzB6TURBMU1UVXhPVE16TXpCYQpNQ014SVRBZkJnTlZCQU1NR0dzemN5MXpaWEoyWlhJdFkyRkFNVFU0T1RjME5EQXhNREJaTUJNR0J5cUdTTTQ5CkFnRUdDQ3FHU000OUF3RUhBMElBQlBLeDcrMmZzQjY2Ti9qaHNEbWRKbW9hSHJJZEhyNFlSNC9mdi9HOVo5czIKWlRxZkxGS3ZMVEdVR1kzWDR6WStnbk0xbGlTWmU3dTZEUDBKTkpzR1FOU2pJekFoTUE0R0ExVWREd0VCL3dRRQpBd0lDcERBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDSUZMODN4eFRPOVp4CnZiY056bk9tdW0zRlJrRDNiZG9rNDZjZkxZMGtPTG5FQWlFQXBLNzhESXlTZnVIZytZS09FcCs2M1E4WlhJbVUKSmlUaGdOMUhQeFRTZjRVPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg<span style="color:#f92672">==</span>
    server: https://127.0.0.1:6443
  name: default
contexts:
- context:
    cluster: default
    user: default
  name: default
current-context: default
kind: Config
preferences: <span style="color:#f92672">{}</span>
users:
- name: default
  user:
    password: 1c8af2866442d22f6a3053ffd776ece9
    username: admin

<span style="color:#75715e"># To get the cluster token needed to configure the worker nodes</span>
$ cat /var/lib/rancher/k3s/server/node-token

K10a3037f19183b43823cb1394f466b489c988c2110b122728821d33eaa4c9f144a::server:28f6e3c31e97e08c0a5ecb500398f931

</code></pre></div><h2 id="worker-nodes">Worker nodes</h2>
<p>On Worker nodes issue de following commands</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Log in to worker1</span>
$ sudo ignite ssh worker1

<span style="color:#75715e"># Install k3s</span>
$ curl -sfL https://get.k3s.io | K3S_URL<span style="color:#f92672">=</span>https://10.61.0.2:6443 K3S_TOKEN<span style="color:#f92672">=</span>K10a3037f19183b43823cb1394f466b489c988c2110b122728821d33eaa4c9f144a::server:28f6e3c31e97e08c0a5ecb500398f931 sh -

<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Finding release <span style="color:#66d9ef">for</span> channel stable
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Using v1.18.2+k3s1 as release
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Downloading hash https://github.com/rancher/k3s/releases/download/v1.18.2+k3s1/sha256sum-amd64.txt
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Downloading binary https://github.com/rancher/k3s/releases/download/v1.18.2+k3s1/k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Verifying binary download
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Installing k3s to /usr/local/bin/k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/kubectl symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/crictl symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/ctr symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating killall script /usr/local/bin/k3s-killall.sh
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating uninstall script /usr/local/bin/k3s-agent-uninstall.sh
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  env: Creating environment file /etc/systemd/system/k3s-agent.service.env
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  systemd: Creating service file /etc/systemd/system/k3s-agent.service
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  systemd: Enabling k3s-agent unit
Created symlink /etc/systemd/system/multi-user.target.wants/k3s-agent.service → /etc/systemd/system/k3s-agent.service.
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  systemd: Starting k3s-agent

$ exit

<span style="color:#75715e"># Now log to worker2</span>
$ sudo ignite ssh worker2

<span style="color:#75715e"># Install k3s</span>
$ curl -sfL https://get.k3s.io | K3S_URL<span style="color:#f92672">=</span>https://10.61.0.2:6443 K3S_TOKEN<span style="color:#f92672">=</span>K10a3037f19183b43823cb1394f466b489c988c2110b122728821d33eaa4c9f144a::server:28f6e3c31e97e08c0a5ecb500398f931 sh -

<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Finding release <span style="color:#66d9ef">for</span> channel stable
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Using v1.18.2+k3s1 as release
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Downloading hash https://github.com/rancher/k3s/releases/download/v1.18.2+k3s1/sha256sum-amd64.txt
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Downloading binary https://github.com/rancher/k3s/releases/download/v1.18.2+k3s1/k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Verifying binary download
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Installing k3s to /usr/local/bin/k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/kubectl symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/crictl symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating /usr/local/bin/ctr symlink to k3s
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating killall script /usr/local/bin/k3s-killall.sh
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  Creating uninstall script /usr/local/bin/k3s-agent-uninstall.sh
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  env: Creating environment file /etc/systemd/system/k3s-agent.service.env
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  systemd: Creating service file /etc/systemd/system/k3s-agent.service
<span style="color:#f92672">[</span>INFO<span style="color:#f92672">]</span>  systemd: Enabling k3s-agent unit
Created symlink /etc/systemd/system/multi-user.target.wants/

</code></pre></div><h2 id="check-the-installation">Check the installation</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># On the master node run</span>
$ kubectl get nodes -o wide

NAME      STATUS   ROLES    AGE     VERSION        INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME
master    Ready    master   10m     v1.18.2+k3s1   10.61.0.2     &lt;none&gt;        Ubuntu 18.04.4 LTS   4.19.47          containerd://1.3.3-k3s2
worker1   Ready    &lt;none&gt;   3m20s   v1.18.2+k3s1   10.61.0.3     &lt;none&gt;        Ubuntu 18.04.4 LTS   4.19.47          containerd://1.3.3-k3s2
worker2   Ready    &lt;none&gt;   17s     v1.18.2+k3s1   10.61.0.4     &lt;none&gt;        Ubuntu 18.04.4 LTS   4.19.47          containerd://1.3.3-k3s2

<span style="color:#75715e"># Check pods running in the fhresly installed cluster</span>
$ kubectl get pods --all-namespaces

NAMESPACE     NAME                                     READY   STATUS      RESTARTS   AGE
kube-system   local-path-provisioner-6d59f47c7-mhfjf   1/1     Running     <span style="color:#ae81ff">0</span>          14m
kube-system   metrics-server-7566d596c8-gfbj5          1/1     Running     <span style="color:#ae81ff">0</span>          14m
kube-system   helm-install-traefik-wkmjw               0/1     Completed   <span style="color:#ae81ff">0</span>          14m
kube-system   coredns-8655855d6-588ln                  1/1     Running     <span style="color:#ae81ff">0</span>          14m
kube-system   svclb-traefik-z94lc                      2/2     Running     <span style="color:#ae81ff">0</span>          13m
kube-system   traefik-758cd5fc85-tcgl4                 1/1     Running     <span style="color:#ae81ff">0</span>          13m
kube-system   svclb-traefik-smfch                      2/2     Running     <span style="color:#ae81ff">0</span>          7m16s
kube-system   svclb-traefik-4c8cx                      2/2     Running     <span style="color:#ae81ff">0</span>          4m12s

<span style="color:#75715e"># Check services running</span>
$ kubectl get services --all-namespaces

NAMESPACE     NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>                      AGE
default       kubernetes           ClusterIP      10.43.0.1       &lt;none&gt;        443/TCP                      15m
kube-system   kube-dns             ClusterIP      10.43.0.10      &lt;none&gt;        53/UDP,53/TCP,9153/TCP       15m
kube-system   metrics-server       ClusterIP      10.43.116.88    &lt;none&gt;        443/TCP                      15m
kube-system   traefik-prometheus   ClusterIP      10.43.228.116   &lt;none&gt;        9100/TCP                     15m
kube-system   traefik              LoadBalancer   10.43.143.31    10.61.0.2     80:32686/TCP,443:31374/TCP   15m

</code></pre></div><p>As we can see out of the box we have services and pods running already. In fact, k3s basic installation installed traefik as ingress controller and load balancers on by default on port 80 and 443, which means we already have an ingress proxy running in all the nodes in the cluster running in those ports. And any service we create as a load balancer on a specific port will be available in all nodes.</p>
<h2 id="run-some-basic-workload">Run some basic workload</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># Run an echoserver to test the installation</span>
$ kubectl create deployment hello-node --image<span style="color:#f92672">=</span>k8s.gcr.io/echoserver:1.4

deployment.apps/hello-node created

<span style="color:#75715e"># Show the deployment</span>
$ kubectl get deployments

NAME         READY   UP-TO-DATE   AVAILABLE   AGE
hello-node   1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           29s

<span style="color:#75715e"># Show the pods running</span>
$ kubectl get pods

NAME                          READY   STATUS    RESTARTS   AGE
hello-node-7bf657c596-cfp6q   1/1     Running   <span style="color:#ae81ff">0</span>          3m10s

<span style="color:#75715e"># WE can expose the service as load balanced in port 8080 with the ingress coontroller</span>
$ kubectl expose deployment hello-node --type<span style="color:#f92672">=</span>LoadBalancer --port<span style="color:#f92672">=</span><span style="color:#ae81ff">8080</span>

service/hello-node exposed


<span style="color:#75715e"># Show services running as we can see the service load balaced with external IP 10.61.0.4 which is one of the nodes</span>
$ kubectl get services

NAME         TYPE           CLUSTER-IP     EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>          AGE
kubernetes   ClusterIP      10.43.0.1      &lt;none&gt;        443/TCP          25m
hello-node   LoadBalancer   10.43.144.49   10.61.0.4     8080:31371/TCP   41s

<span style="color:#75715e"># If we show pods again we can see after exposing it through the ingress controller we have 3 pods which are the proxies set by the load balancer which got exposed in all node on port 8080</span>
$ kubectl get pods

NAME                          READY   STATUS    RESTARTS   AGE
hello-node-7bf657c596-cfp6q   1/1     Running   <span style="color:#ae81ff">0</span>          8m8s
svclb-hello-node-n4knw        1/1     Running   <span style="color:#ae81ff">0</span>          4m34s
svclb-hello-node-7sbnw        1/1     Running   <span style="color:#ae81ff">0</span>          4m34s
svclb-hello-node-w2tnp        1/1     Running   <span style="color:#ae81ff">0</span>          4m34s


<span style="color:#75715e"># Now from the host running the vms or any of the worker nodes we can hit our ingress controller</span>
$ curl http://10.61.0.4:8080
CLIENT VALUES:
client_address<span style="color:#f92672">=</span>10.42.0.0
command<span style="color:#f92672">=</span>GET
real path<span style="color:#f92672">=</span>/
query<span style="color:#f92672">=</span>nil
request_version<span style="color:#f92672">=</span>1.1
request_uri<span style="color:#f92672">=</span>http://10.61.0.4:8080/

SERVER VALUES:
server_version<span style="color:#f92672">=</span>nginx: 1.10.0 - lua: <span style="color:#ae81ff">10001</span>

HEADERS RECEIVED:
accept<span style="color:#f92672">=</span>*/*
host<span style="color:#f92672">=</span>10.61.0.4:8080
user-agent<span style="color:#f92672">=</span>curl/7.58.0
BODY:
-no body in request-

<span style="color:#75715e"># but since the ingress contrioller is running in all nodes we can try all other node ips</span>
$ curl http://10.61.0.3:8080
CLIENT VALUES:
client_address<span style="color:#f92672">=</span>10.42.1.3
command<span style="color:#f92672">=</span>GET
real path<span style="color:#f92672">=</span>/
query<span style="color:#f92672">=</span>nil
request_version<span style="color:#f92672">=</span>1.1
request_uri<span style="color:#f92672">=</span>http://10.61.0.3:8080/

SERVER VALUES:
server_version<span style="color:#f92672">=</span>nginx: 1.10.0 - lua: <span style="color:#ae81ff">10001</span>

HEADERS RECEIVED:
accept<span style="color:#f92672">=</span>*/*
host<span style="color:#f92672">=</span>10.61.0.3:8080
user-agent<span style="color:#f92672">=</span>curl/7.58.0
BODY:
-no body in request-

$ curl http://10.61.0.2:8080
CLIENT VALUES:
client_address<span style="color:#f92672">=</span>10.42.0.8
command<span style="color:#f92672">=</span>GET
real path<span style="color:#f92672">=</span>/
query<span style="color:#f92672">=</span>nil
request_version<span style="color:#f92672">=</span>1.1
request_uri<span style="color:#f92672">=</span>http://10.61.0.2:8080/

SERVER VALUES:
server_version<span style="color:#f92672">=</span>nginx: 1.10.0 - lua: <span style="color:#ae81ff">10001</span>

HEADERS RECEIVED:
accept<span style="color:#f92672">=</span>*/*
host<span style="color:#f92672">=</span>10.61.0.2:8080
user-agent<span style="color:#f92672">=</span>curl/7.58.0
BODY:
-no body in request-

</code></pre></div><h1 id="conclusion">Conclusion</h1>
<p>It is pretty easy to run this setup and you will get a nice way to run a few nodes on a local laptop, which will allow to learn and develop kubernetes features but still having a simple way to install it.<br>
There are many ways to have a similar setup with other projects or distributions, in my case I needed to have the nodes running as independent vms, but there are other projects like minikube or microk8s which give similar features to develop locally with k8s in mind, each project have it&rsquo;s advantages and disadvantanges, at this time it made sense to me to try this particular approach, probably in future posts I will be playing around with other k8s distributions as well as other virtualization for different use cases.<br>
The major hurdle I found with this project was that I wanted to run this in my Mac Laptop and since firecraker relies on kvm for virtualization it is not possible to run it on mac, I might be showing how to do something similar on a Mac in a future post if I find something that convinces me.<br>
Some follow up tasks would be to test this setup using <a href="https://multipass.run/">multipass</a> which suports <code>Hypervisor.framework / hyperkit</code> as a backend as well as <code>virtualbox</code> to start ubuntu vms, to be honest I have&rsquo;nt tested it yet, but looks good so stay tunned for following posts.</p>

    </div>
</div><div id="social-media-share" class="has-text-centered">
	<p><i>Sharing is caring!</i></p>
	<br>
	
	<div class="share-buttons">
	    <a  href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2fpancho.dev%2fposts%2fmultinode-k8s-ignite-k3s%2f"
	        onclick="socialMediaPopUp(this.href, '', 500, 500); return false;"
	        title="Share on Facebook. Opens in a new window.">
	        <img src=/img/icons/45px/facebook.png>
	    </a>

	    <a  href="https://twitter.com/intent/tweet?text=Multinode%20k8s%20cluster%20using%20ignite%20and%20k3s&url=http%3a%2f%2fpancho.dev%2fposts%2fmultinode-k8s-ignite-k3s%2f"
	        onclick="socialMediaPopUp(this.href, '', 500, 500); return false;"
	        title="Share on Twitter. Opens in a new window." >
	        <img src=/img/icons/45px/twitter.png>
	    </a>

		<a  href="http://www.reddit.com/submit?url=http%3a%2f%2fpancho.dev%2fposts%2fmultinode-k8s-ignite-k3s%2f"
	        onclick="socialMediaPopUp(this.href, '', 900, 500); return false;"
	        title="Share on Reddit. Opens in a new window." >
	        <img src=/img/icons/45px/reddit.png>
	    </a>

	    <a  href="http://pinterest.com/pin/create/button/?url=http%3a%2f%2fpancho.dev%2fposts%2fmultinode-k8s-ignite-k3s%2f"
	        onclick="socialMediaPopUp(this.href, '', 900, 500); return false;"
	        title="Share on Pinterest. Opens in a new window." >
	        <img src=/img/icons/45px/pinterest.png>
	    </a>

	    <a  href="http://www.tumblr.com/share/link?url=http%3a%2f%2fpancho.dev%2fposts%2fmultinode-k8s-ignite-k3s%2f"
	        onclick="socialMediaPopUp(this.href, '', 900, 500); return false;"
	        title="Share on Tumblr. Opens in a new window." >
	        <img src=/img/icons/45px/tumblr.png>
	    </a>

		<a  href="https://www.linkedin.com/shareArticle?mini=true&url=http%3a%2f%2fpancho.dev%2fposts%2fmultinode-k8s-ignite-k3s%2f
			&title=Multinode%20k8s%20cluster%20using%20ignite%20and%20k3s&summary=Sometimes%20if%20you%20are%20working%20with%20kubernetes%2c%20or%20developing%20applications%20that%20require%20a%20multinode%20setup%20to%20test%20some%20functionality%20running%20a%20multinode%20cluster%20is%20a%20must%2c%20in%20some%20cases%20you%20could%20use%20kind%20which%20you%20can%20spin%20up%20multinode%2fmultimaster%20clusters%20on%20docker%2c%20however%20there%20might%20be%20scenarios%20were%20you%20still%20need%20to%20test%20or%20develop%20functions%20that%20need%20the%20real%20feel%20of%20a%20cluster%20with%20multiple%20nodes.%0aIn%20the%20past%20I%20have%20run%20this%20in%20my%20local%20environment%20running%20vms%20with%20vagrant%20and%20virtualbox%2c%20that%20worked%20very%20well%2c%20and%20I%20still%20use%20it%20for%20some%20special%20scenarios.&source=rafed123.github.io"
	        onclick="socialMediaPopUp(this.href, '', 900, 500); return false;"
	        title="Share on LinkedIn. Opens in a new window." >
	        <img src=/img/icons/45px/linkedin.png>
	    </a>

	    <a  href="mailto:?subject=Multinode%20k8s%20cluster%20using%20ignite%20and%20k3s&amp;body=Check out this site http%3a%2f%2fpancho.dev%2fposts%2fmultinode-k8s-ignite-k3s%2f"
	        title="Share via Email. Opens in a new window." >
	        <img src=/img/icons/45px/mail.png>
	    </a>
	</div>
</div>


<br>
<div id="disqus_thread"></div>
<script type="text/javascript">
    (function () {
        
        
        if (window.location.hostname == "localhost")
            return;

        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        var disqus_shortname = '';
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


        </div>
    </div>

<footer class="footer has-background-dark">
    <div class="content has-text-centered has-text-white">
        <p>
            © 2020 Ramium. Powered by
            <a class="has-text-light" href="https://github.com/gohugoio/hugo" target="_blank">
            Hugo</a>. Theme
            <a class="has-text-light" href="https://github.com/rafed123/ramium/" target="_blank">
                Ramium.
            </a>
        </p>
    </div>
</footer>
</body>

</html>